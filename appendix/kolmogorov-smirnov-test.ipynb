{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ababfab",
   "metadata": {},
   "source": [
    "# Module 1 | Random Number Generators: Implementation and Applications\n",
    "\n",
    "## Kolmogorov-Smirnov Test: Statistical Analysis of Randomness\n",
    "\n",
    "The **Kolmogorov-Smirnov (KS) test** is a **non-parametric statistical test** used to compare a sample with a reference probability distribution (one-sample KS test) or to compare two independent samples (two-sample KS test). It is used to determine whether a given sample follows a specified distribution or whether two samples are drawn from the same distribution.\n",
    "\n",
    "### 1. **One-Sample KS Test**\n",
    "\n",
    "This test compares an empirical cumulative distribution function (**ECDF**) of a sample with a theoretical cumulative distribution function (**CDF**) of a reference distribution (e.g., normal, uniform). It tests the null hypothesis:\n",
    "\n",
    "$$\n",
    "H_0: F(x) = F_0(x) \\quad \\text{for all } x\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ F(x) $ is the empirical CDF of the sample.\n",
    "- $ F_0(x) $ is the CDF of the theoretical distribution.\n",
    "\n",
    "The **test statistic** is:\n",
    "\n",
    "$$\n",
    "D_n = \\sup_x |F_n(x) - F_0(x)|\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ F_n(x) $ is the empirical CDF based on $ n $ observations.\n",
    "- $ \\sup_x $ denotes the **supremum** (maximum absolute difference).\n",
    "\n",
    "A large $ D_n $ suggests that the sample does not follow $ F_0(x) $, and the null hypothesis is rejected.\n",
    "\n",
    "### 2. **Two-Sample KS Test**\n",
    "\n",
    "This test compares the empirical distributions of two independent samples, testing whether they come from the same underlying distribution. The null hypothesis is:\n",
    "\n",
    "$$\n",
    "H_0: F_1(x) = F_2(x) \\quad \\text{for all } x\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ F_1(x) $ and $ F_2(x) $ are the empirical CDFs of the two samples.\n",
    "\n",
    "The **test statistic** is:\n",
    "\n",
    "$$\n",
    "D_{n,m} = \\sup_x |F_n(x) - G_m(x)|\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ F_n(x) $ is the empirical CDF of the first sample (size $ n $).\n",
    "- $ G_m(x) $ is the empirical CDF of the second sample (size $ m $).\n",
    "\n",
    "A large $ D_{n,m} $ suggests that the two distributions differ significantly.\n",
    "\n",
    "### 3. **Interpretation**\n",
    "\n",
    "- The **p-value** indicates the probability of observing the test statistic under $ H_0 $. A small p-value (e.g., $ p < 0.05 $) suggests rejecting $ H_0 $.\n",
    "- The test is **sensitive to differences in both location and shape** between distributions.\n",
    "- It works well with **continuous distributions** but may be less reliable for discrete distributions.\n",
    "\n",
    "### 4. **Implementation in Python**\n",
    "\n",
    "Using `scipy.stats.kstest` for a **one-sample KS test**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kstest, norm\n",
    "\n",
    "# Generate sample data\n",
    "sample = np.random.normal(loc=0, scale=1, size=100)  # Standard normal sample\n",
    "\n",
    "# Perform KS test against normal distribution\n",
    "ks_stat, p_value = kstest(sample, 'norm')\n",
    "\n",
    "print(f\"KS Statistic: {ks_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d0fa9",
   "metadata": {},
   "source": [
    "Using `scipy.stats.ks_2samp` for a **two-sample KS test**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28345e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Generate two different distributions\n",
    "sample1 = np.random.normal(0, 1, 100)\n",
    "sample2 = np.random.uniform(-1, 1, 100)\n",
    "\n",
    "# Perform two-sample KS test\n",
    "ks_stat, p_value = ks_2samp(sample1, sample2)\n",
    "\n",
    "print(f\"KS Statistic: {ks_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0f35e",
   "metadata": {},
   "source": [
    "### 5. **Advantages**\n",
    "\n",
    "- **Non-parametric**: No assumptions about the data distribution.\n",
    "- **Sensitive to shape differences** between distributions.\n",
    "- **Works with small sample sizes**.\n",
    "\n",
    "### 6. **Limitations**\n",
    "\n",
    "- Less powerful than parametric tests when assumptions hold (e.g., t-test for normal distributions).\n",
    "- May be **too sensitive** with large sample sizes, detecting minor differences that are not practically significant.\n",
    "- Less reliable for discrete data."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
